{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part III: LLM\n",
    "\n",
    "Please see the description of the assignment in the README file (section 3) <br>\n",
    "**Guide notebook**: [guides/llm_guide.ipynb](guides/llm_guide.ipynb)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "* Note that you should report results using a classification report. \n",
    "\n",
    "* Also, remember to include some reflections on your results: how do they compare with the results from Part I, BoW?, and part II, BERT? Are there any hyperparameters or prompting techniques that are particularly important?\n",
    "\n",
    "* You should follow the steps given in the `llm_guide` notebook\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watsonx API Key: Kh-sgOv8q7LagG5N--kjCAOkfKhUcR9hOpfkjwVxpL4Z\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the Watsonx API key\n",
    "WX_API_KEY = os.getenv(\"WX_API_KEY\")\n",
    "\n",
    "# Print or use the key\n",
    "print(\"Watsonx API Key:\", WX_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the project\n",
    "\n",
    "import pandas as pd\n",
    "from decouple import config\n",
    "from ibm_watsonx_ai import APIClient\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WX_API_KEY = config('WX_API_KEY')\n",
    "\n",
    "credentials = Credentials(\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key = WX_API_KEY\n",
    ")\n",
    "\n",
    "client = APIClient(\n",
    "    credentials=credentials, \n",
    "    project_id=\"75de42c2-d0c2-4185-b732-8bf50d64f880\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"ibm/granite-3-8b-instruct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'ibm/granite-3-8b-instruct',\n",
       " 'model_version': '1.1.0',\n",
       " 'created_at': '2025-03-30T12:56:03.569Z',\n",
       " 'results': [{'generated_text': '\\n\\n1. Find a safe, open area to practice.\\n2. Adjust the seat to',\n",
       "   'generated_token_count': 20,\n",
       "   'input_token_count': 10,\n",
       "   'stop_reason': 'max_tokens'}],\n",
       " 'system': {'warnings': [{'message': \"The value of 'parameters.max_new_tokens' for this model was set to value 20\",\n",
       "    'id': 'unspecified_max_new_tokens',\n",
       "    'additional_properties': {'limit': 0,\n",
       "     'new_value': 20,\n",
       "     'parameter': 'parameters.max_new_tokens',\n",
       "     'value': 0}}]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"How do I ride a bicycle?\"\n",
    "generated_response = model.generate(prompt)\n",
    "\n",
    "generated_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| PARAMETER             | TYPE                                   | EXAMPLE VALUE                                                                                                                             |\n",
      "+=======================+========================================+===========================================================================================================================================+\n",
      "| decoding_method       | str, TextGenDecodingMethod, NoneType   | sample                                                                                                                                    |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| length_penalty        | dict, TextGenLengthPenalty, NoneType   | {'decay_factor': 2.5, 'start_index': 5}                                                                                                   |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| temperature           | float, NoneType                        | 0.5                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| top_p                 | float, NoneType                        | 0.2                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| top_k                 | int, NoneType                          | 1                                                                                                                                         |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| random_seed           | int, NoneType                          | 33                                                                                                                                        |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| repetition_penalty    | float, NoneType                        | 2                                                                                                                                         |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| min_new_tokens        | int, NoneType                          | 50                                                                                                                                        |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| max_new_tokens        | int, NoneType                          | 1000                                                                                                                                      |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| stop_sequences        | list, NoneType                         | 200                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| time_limit            | int, NoneType                          | 600000                                                                                                                                    |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| truncate_input_tokens | int, NoneType                          | 200                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| return_options        | dict, ReturnOptionProperties, NoneType | {'input_text': True, 'generated_tokens': True, 'input_tokens': True, 'token_logprobs': True, 'token_ranks': False, 'top_n_tokens': False} |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| include_stop_sequence | bool, NoneType                         | True                                                                                                                                      |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| prompt_variables      | dict, NoneType                         | {'doc_type': 'emails', 'entity_name': 'Golden Retail'}                                                                                    |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from ibm_watsonx_ai.foundation_models.schema import TextGenParameters\n",
    "\n",
    "TextGenParameters.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = TextGenParameters(\n",
    "    temperature=0.8,      # Higher temperature means more randomness\n",
    "    max_new_tokens=500, # Maximum number of tokens to generate\n",
    "    min_new_tokens=200, # Minimum number of tokens to generate\n",
    ")\n",
    "\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"ibm/granite-3-8b-instruct\",\n",
    "    params=PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "We can load this data directly from [Hugging Face Datasets](https://huggingface.co/docs/datasets/) - The HuggingFace Hub- into a Pandas DataFrame. Pretty neat!\n",
    "\n",
    "**Note**: This cell will download the dataset and keep it in memory. If you run this cell multiple times, it will download the dataset multiple times.\n",
    "\n",
    "You are welcome to increase the `frac` parameter to load more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "# train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((760, 2),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Sci/Tech'\n",
    "}\n",
    "\n",
    "def preprocess(df: pd.DataFrame, frac = 1e-2, label_map = label_map, seed=42) -> pd.DataFrame:\n",
    "    return  (\n",
    "        df\n",
    "        .assign(label=lambda x: x['label'].map(label_map))\n",
    "        [lambda df: df['label'].isin(label_map.values())]\n",
    "        .groupby('label')\n",
    "        .apply(lambda x: x.sample(frac=frac, random_state=seed))\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    )\n",
    "\n",
    "# train_df = preprocess(train, frac=0.01)\n",
    "test_df = preprocess(test, frac=0.1)\n",
    "\n",
    "# clear up some memory by deleting the original dataframes\n",
    "# del train\n",
    "del test\n",
    "\n",
    "test_df.shape, # train_df.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'ibm/granite-3-8b-instruct',\n",
       " 'model_version': '1.1.0',\n",
       " 'created_at': '2025-03-30T12:56:45.204Z',\n",
       " 'results': [{'generated_text': \"\\n\\nRiding a bicycle involves several steps. Here's a simple guide to help you get started:\\n\\n1. **Find a suitable bicycle**: Ensure the bike fits you properly. Your knees should have a slight bend when the pedal is at its lowest point.\\n\\n2. **Adjust the seat and handlebars**: Lower the seat so your leg is extended slightly when the pedal is at its lowest point. Adjust the handlebars to a comfortable height.\\n\\n3. **Put on safety gear**: Wear a helmet, gloves, and comfortable shoes.\\n\\n4. **Start in a safe area**: Find a flat, open space like a park or parking lot.\\n\\n5. **Learn to balance**: Sit on the bike, place your feet on the ground, and walk the bike forward a few steps.\\n\\n6. **Practice pedaling**: Lift your feet off the ground, while keeping your balance. Start pedaling slowly.\\n\\n   - **For beginners, it's easier to use training wheels or a balance bike initially.**\\n\\n7. **Steering**: To turn, lean your body and look in the direction you want to go.\\n\\n8. **Braking**: Practice using the brakes gently and consistently. Apply the brakes to slow down or stop.\\n\\n9. **Master starting and stopping**: To start moving, push off the ground with one foot while pedaling with the other. To stop, apply the brakes gradually.\\n\\n10. **Practice**: Spend time riding and gaining confidence. Gradually increase the difficulty by riding on slightly hilly terrain, roads, and eventually trails or bike paths.\\n\\n11. **Stay safe**: Always follow traffic rules, use hand signals, and wear reflective gear for visibility.\\n\\nRemember, practice and patience are essential when learning to ride a bicycle. You may need help from friends or family to provide support and guidance. Additionally, consider enrolling in a bike safety course or taking lessons from a local bike shop or cycling club to improve your skills and gain confidence.\\n\\nOnce you're comfortable riding, explore different types of bicycles, such as road, mountain, or hybrid b\",\n",
       "   'generated_token_count': 500,\n",
       "   'input_token_count': 10,\n",
       "   'stop_reason': 'max_tokens'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.generate(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Riding a bicycle involves several steps. Here's a simple guide to help you get started:\n",
      "\n",
      "1. **Find a suitable bicycle**: Ensure the bike fits you properly. Your knees should have a slight bend when the pedal is at its lowest point.\n",
      "\n",
      "2. **Adjust the seat and handlebars**: Lower the seat so your leg is extended slightly when the pedal is at its lowest point. Adjust the handlebars to a comfortable height.\n",
      "\n",
      "3. **Put on safety gear**: Wear a helmet, gloves, and comfortable shoes.\n",
      "\n",
      "4. **Start in a safe area**: Find a flat, open space like a park or parking lot.\n",
      "\n",
      "5. **Learn to balance**: Sit on the bike, place your feet on the ground, and walk the bike forward a few steps.\n",
      "\n",
      "6. **Practice pedaling**: Lift your feet off the ground, while keeping your balance. Start pedaling slowly.\n",
      "\n",
      "   - **For beginners, it's easier to use training wheels or a balance bike initially.**\n",
      "\n",
      "7. **Steering**: To turn, lean your body and look in the direction you want to go.\n",
      "\n",
      "8. **Braking**: Practice using the brakes gently and consistently. Apply the brakes to slow down or stop.\n",
      "\n",
      "9. **Master starting and stopping**: To start moving, push off the ground with one foot while pedaling with the other. To stop, apply the brakes gradually.\n",
      "\n",
      "10. **Practice**: Spend time riding and gaining confidence. Gradually increase the difficulty by riding on slightly hilly terrain, roads, and eventually trails or bike paths.\n",
      "\n",
      "11. **Stay safe**: Always follow traffic rules, use hand signals, and wear reflective gear for visibility.\n",
      "\n",
      "Remember, practice and patience are essential when learning to ride a bicycle. You may need help from friends or family to provide support and guidance. Additionally, consider enrolling in a bike safety course or taking lessons from a local bike shop or cycling club to improve your skills and gain confidence.\n",
      "\n",
      "Once you're comfortable riding, explore different types of bicycles, such as road, mountain, or hybrid b\n"
     ]
    }
   ],
   "source": [
    "print(response[\"results\"][0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "# train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Sci/Tech'\n",
    "}\n",
    "\n",
    "def preprocess(df: pd.DataFrame, frac : float = 1e-2, label_map : dict[int, str] = label_map, seed : int = 42) -> pd.DataFrame:\n",
    "\n",
    "    return  (\n",
    "        df\n",
    "        .assign(label=lambda x: x['label'].map(label_map))\n",
    "        [lambda df: df['label'].isin(label_map.values())]\n",
    "        .groupby('label')[[\"text\", \"label\"]]\n",
    "        .apply(lambda x: x.sample(frac=frac, random_state=seed))\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    )\n",
    "\n",
    "# train_df = preprocess(train, frac=0.01)\n",
    "test_df = preprocess(test, frac=0.1)\n",
    "\n",
    "# clear up some memory by deleting the original dataframes\n",
    "# del train\n",
    "del test\n",
    "\n",
    "test_df.shape # , train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = TextGenParameters(\n",
    "    temperature=0,              # Higher temperature means more randomness - In this case we don't want randomness\n",
    "    max_new_tokens=10,          # Maximum number of tokens to generate\n",
    "    stop_sequences=[\".\", \"\\n\"], # Stop generating text when these sequences are encountered\n",
    ")\n",
    "\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"ibm/granite-3-8b-instruct\",  # We could also try a larger model!\n",
    "    params=PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You task is to classify news stories into one of five categories\n",
    "\n",
    "CATEGORIES:\n",
    "{categories}\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\n",
    "Please assign the correct category to the text. Answer with the correct category and nothing else.\n",
    "\n",
    "Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [03:38<00:00,  3.47it/s]\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = \"- \" + \"\\n- \".join(test_df[\"label\"].unique())  # Create a string with all categories\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for text in tqdm(test_df[\"text\"]):\n",
    "\n",
    "    # format the prompt with the categories and the text\n",
    "    prompt = SYSTEM_PROMPT.format(categories=CATEGORIES, text=text)\n",
    "    \n",
    "    # generate the response from the model\n",
    "    response = model.generate(prompt)\n",
    "\n",
    "    # extract the generated text from the response\n",
    "    prediction = response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # append the prediction to the list of predictions\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00         0\n",
      "  - Business       0.00      0.00      0.00         0\n",
      "    Business       0.65      0.94      0.77       190\n",
      "    Sci/Tech       0.90      0.55      0.68       190\n",
      "      Sports       0.96      0.92      0.94       190\n",
      "       World       0.88      0.82      0.84       190\n",
      "\n",
      "    accuracy                           0.80       760\n",
      "   macro avg       0.57      0.54      0.54       760\n",
      "weighted avg       0.85      0.80      0.81       760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df.label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [03:31<00:00,  3.59it/s]\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|██████████| 760/760 [03:35<00:00,  3.53it/s]\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|██████████| 760/760 [03:39<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Config: {'temperature': 0.0, 'max_new_tokens': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.64      0.97      0.77       183\n",
      "    Sci/Tech       0.00      0.00      0.00        81\n",
      "      Sports       0.96      0.93      0.94       188\n",
      "       World       0.88      0.85      0.86       183\n",
      "\n",
      "    accuracy                           0.80       635\n",
      "   macro avg       0.62      0.69      0.64       635\n",
      "weighted avg       0.72      0.80      0.75       635\n",
      "\n",
      "\n",
      "🔧 Config: {'temperature': 0.5, 'max_new_tokens': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.60      0.97      0.74       179\n",
      "    Sci/Tech       0.00      0.00      0.00        85\n",
      "      Sports       0.95      0.90      0.92       174\n",
      "       World       0.88      0.79      0.83       180\n",
      "\n",
      "    accuracy                           0.77       618\n",
      "   macro avg       0.61      0.67      0.62       618\n",
      "weighted avg       0.70      0.77      0.72       618\n",
      "\n",
      "\n",
      "🔧 Config: {'temperature': 1.0, 'max_new_tokens': 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.59      0.98      0.73       171\n",
      "    Sci/Tech       0.00      0.00      0.00        76\n",
      "      Sports       0.93      0.81      0.86       146\n",
      "       World       0.81      0.71      0.75       150\n",
      "\n",
      "    accuracy                           0.72       543\n",
      "   macro avg       0.58      0.62      0.59       543\n",
      "weighted avg       0.66      0.72      0.67       543\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/marcuskrarup/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define a list of hyperparameter configurations to test\n",
    "hyperparameter_configs = [\n",
    "    {\"temperature\": 0.0, \"max_new_tokens\": 10},\n",
    "    {\"temperature\": 0.5, \"max_new_tokens\": 20},\n",
    "    {\"temperature\": 1.0, \"max_new_tokens\": 50},\n",
    "]\n",
    "\n",
    "# Define valid categories based on your label_map\n",
    "valid_categories = set(label_map.values())\n",
    "\n",
    "# Normalize model prediction\n",
    "def normalize_prediction(pred):\n",
    "    pred = pred.strip().lower()\n",
    "    pred = pred.replace(\"-\", \"\").replace(\":\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    pred = pred.split(\"###\")[0].strip()\n",
    "    return pred.capitalize()\n",
    "\n",
    "# Store results for each configuration\n",
    "results = []\n",
    "\n",
    "for config in hyperparameter_configs:\n",
    "    # Update the parameters\n",
    "    PARAMS = TextGenParameters(\n",
    "        temperature=config[\"temperature\"],\n",
    "        max_new_tokens=config[\"max_new_tokens\"],\n",
    "        stop_sequences=[\"\\n\", \".\", \"\\nCategory:\"]\n",
    "    )\n",
    "    \n",
    "    # Update the model with new parameters\n",
    "    model = ModelInference(\n",
    "        api_client=client,\n",
    "        model_id=\"ibm/granite-3-8b-instruct\",\n",
    "        params=PARAMS\n",
    "    )\n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    # Generate predictions for the test set\n",
    "    for text, label in tqdm(zip(test_df[\"text\"], test_df[\"label\"]), total=len(test_df)):\n",
    "        prompt = SYSTEM_PROMPT.format(categories=CATEGORIES, text=text)\n",
    "        response = model.generate(prompt)\n",
    "        raw_pred = response[\"results\"][0][\"generated_text\"].strip()\n",
    "        clean_pred = normalize_prediction(raw_pred)\n",
    "\n",
    "        if clean_pred in valid_categories:\n",
    "            predictions.append(clean_pred)\n",
    "        else:\n",
    "            predictions.append(\"Unknown\")  # You could also skip it instead\n",
    "\n",
    "        true_labels.append(label)\n",
    "\n",
    "    # Evaluate predictions — exclude Unknown for clean metric\n",
    "    filtered_true = [t for t, p in zip(true_labels, predictions) if p != \"Unknown\"]\n",
    "    filtered_pred = [p for p in predictions if p != \"Unknown\"]\n",
    "\n",
    "    report = classification_report(filtered_true, filtered_pred, output_dict=True)\n",
    "    results.append({\n",
    "        \"config\": config,\n",
    "        \"report\": report,\n",
    "        \"predictions\": predictions\n",
    "    })\n",
    "\n",
    "# Print results per configuration\n",
    "for result in results:\n",
    "    print(f\"\\n🔧 Config: {result['config']}\")\n",
    "    print(classification_report(\n",
    "        [t for t, p in zip(test_df.label, result[\"predictions\"]) if p != \"Unknown\"],\n",
    "        [p for p in result[\"predictions\"] if p != \"Unknown\"]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM\n",
    "The LLM performed well in zero-shot classification with minimal setup. Prompt engineering e.g. clean category lists, stop sequences, and prediction normalization was key to improving accuracy. While not as precise as BERT, the LLM offered flexibility and required no training, making it ideal for rapid experimentation.\n",
    "\n",
    "### BoW\n",
    "The BoW model was fast and simple but lacked contextual understanding. It struggled with nuanced or varied phrasing, resulting in lower accuracy. It served well as a baseline but was outperformed by the two other models.\n",
    "\n",
    "### BERT\n",
    "BERT achieved the best overall performance, thanks to its deep contextual understanding. It handled complex language and subtle distinctions effectively. However, it required more resources and training time. It’s the most reliable choice for high-stakes classification tasks.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
